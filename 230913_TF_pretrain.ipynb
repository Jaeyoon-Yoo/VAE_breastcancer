{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "pd.set_option('mode.chained_assignment',  None)\n",
    "import os\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('TF_in_data_all.pickle', 'rb') as f:\n",
    "    TF_in_data, TF_in_std, TF_in_mask, ID_list, ID_year_list = pickle.load(f)\n",
    "TF_in_data = TF_in_data.detach().cpu()\n",
    "TF_in_std = TF_in_std.detach().cpu()\n",
    "TF_in_mask = TF_in_mask.detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_dir = './loss'\n",
    "model_dir = './model_save'\n",
    "table_loc_master = \"/data/Storage_DAS02/jaeyoon/230101_BreastCancer_Project/data/230629_BC_new/\"\n",
    "table_data_master = \"230714_Table_merged.xlsx\"\n",
    "table_type_master = \"230714_BC_new_variable_type.xlsx\"\n",
    "\n",
    "Table_type = pd.read_excel(table_loc_master+table_type_master)\n",
    "Table_type= Table_type[Table_type[\"Distribution\"] != \"-\"]\n",
    "Table_type= Table_type[Table_type[\"In VAE\"] != \"X\"]\n",
    "\n",
    "Table_1 = pd.read_excel(table_loc_master+table_data_master).reset_index(drop = True).set_index(['new_ID','Year_num'])\n",
    "Table_Date = Table_1[[\"Test_date_normed\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_test = pd.read_excel(\"Test_ID_set.xlsx\").values[:,1]\n",
    "ID_train = pd.read_excel(\"Train_ID_set.xlsx\").values[:,1]\n",
    "# ID_test = np.unique([i.split(',')[0][2:-1] for i in ID_test])\n",
    "# ID_train = np.unique([i.split(',')[0][2:-1] for i in ID_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader\n",
    "class BART_pretrain_Dataset(Dataset):\n",
    "    def __init__(self, inputs):\n",
    "        TF_in_data, TF_in_mask, ID_list, ID_year_list, ID_use = inputs\n",
    "        idx_sub = [n for n,i in enumerate(ID_list) if i in ID_use]\n",
    "        self.data = TF_in_data[idx_sub] # N, 10, 50\n",
    "        self.mask = TF_in_mask[idx_sub] # N, 10, 1\n",
    "        self.ID_list = np.array(ID_list)[idx_sub]\n",
    "        self.ID_year_list = [i for n,i in enumerate(ID_year_list) if n in idx_sub]\n",
    "        # self.ID_year_list = np.array(ID_year_list)[idx_sub]\n",
    "\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.ID_list)\n",
    "\n",
    "    def __getitem__(self, idx_sub): # N x 260x512\n",
    "        # 260 x 512\n",
    "        return {'data' : self.data[idx_sub],\n",
    "                'mask' : self.mask[idx_sub],\n",
    "                'idx' : self.ID_list[idx_sub],\n",
    "                'data_idx' : self.ID_year_list[idx_sub]}\n",
    "def BART_collate_fn(samples):\n",
    "    p = 0.3\n",
    "    data = torch.stack([sample['data'] for sample in samples]) # N, 10, 50\n",
    "    mask = torch.stack([sample['mask'] for sample in samples]).bool() # N, 10, 1\n",
    "    IDs = [sample['idx'] for sample in samples] # N, 10, 1\n",
    "    Rand_mask = torch.zeros_like(mask)\n",
    "    for n,sample in enumerate(samples):\n",
    "        idx_sub = np.setdiff1d(sample['data_idx'],[1])\n",
    "        if idx_sub.shape[0] != 0:\n",
    "            idx_MLM = np.random.choice(idx_sub,max(1,int(len(idx_sub) * p)),replace = False)            \n",
    "            for idx in idx_MLM:\n",
    "                Rand_mask[n,idx] = 1\n",
    "    Rand_mask = Rand_mask.bool()\n",
    "    Enc_mask = mask + Rand_mask\n",
    "    Enc_in = data * (~Enc_mask)\n",
    "    Out_mask = ~mask\n",
    "    Out_data = data\n",
    "    Dec_in = torch.concat([torch.zeros(data.shape[0],1,data.shape[2]).float(),data[:,:-1,:]], axis = 1)\n",
    "    Dec_mask = torch.concat([torch.zeros(data.shape[0],1,1),mask[:,:-1,:]], axis = 1).repeat(1,1,10).bool()\n",
    "    \n",
    "    return Enc_in, Enc_mask, Dec_in, Dec_mask, Out_mask, Out_data, IDs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionLayer(nn.Module):\n",
    "    def __init__(self, hidden_dim, n_heads, dropout_ratio):\n",
    "        super().__init__()\n",
    "\n",
    "        assert hidden_dim % n_heads == 0\n",
    "        self.hidden_dim = hidden_dim # 임베딩 차원\n",
    "        self.n_heads = n_heads # 헤드(head)의 개수: 서로 다른 어텐션(attention) 컨셉의 수\n",
    "        self.head_dim = hidden_dim // n_heads # 각 헤드(head)에서의 임베딩 차원\n",
    "        self.fc_q = nn.Linear(hidden_dim, hidden_dim) # Query 값에 적용될 FC 레이어\n",
    "        self.fc_k = nn.Linear(hidden_dim, hidden_dim) # Key 값에 적용될 FC 레이어\n",
    "        self.fc_v = nn.Linear(hidden_dim, hidden_dim) # Value 값에 적용될 FC 레이어\n",
    "\n",
    "        self.fc_o = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_ratio)\n",
    "\n",
    "    def forward(self, query, key, value, mask = None):\n",
    "\n",
    "        batch_size = query.shape[0]\n",
    "\n",
    "        Q = self.fc_q(query)\n",
    "        K = self.fc_k(key)\n",
    "        V = self.fc_v(value)\n",
    "\n",
    "        # hidden_dim → n_heads X head_dim 형태로 변형\n",
    "        # n_heads(h)개의 서로 다른 어텐션(attention) 컨셉을 학습하도록 유도\n",
    "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "\n",
    "\n",
    "        # Attention Energy 계산\n",
    "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / math.sqrt(self.hidden_dim)\n",
    "        energy = torch.clamp(energy,max = 1e6, min = -1e6)\n",
    "        # 마스크(mask)를 사용하는 경우\n",
    "        if mask is not None:\n",
    "            energy = energy.masked_fill(mask.unsqueeze(1).repeat(1, self.n_heads, 1, 1), -1e10)\n",
    "        attention = torch.softmax(energy, dim=-1)\n",
    "        \n",
    "        x = torch.matmul(self.dropout(attention), V)\n",
    "        x = x.permute(0, 2, 1, 3).contiguous()\n",
    "        x = x.view(batch_size, -1, self.hidden_dim)\n",
    "        x = self.fc_o(x)\n",
    "\n",
    "        return x, attention\n",
    "    \n",
    "class PositionwiseFeedforwardLayer(nn.Module):\n",
    "    def __init__(self, hidden_dim, pf_dim, dropout_ratio):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc_1 = nn.Linear(hidden_dim, pf_dim)\n",
    "        self.fc_2 = nn.Linear(pf_dim, hidden_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_ratio)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.dropout(torch.relu(self.fc_1(x)))\n",
    "        x = self.fc_2(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, hidden_dim, n_heads, pf_dim, dropout_ratio):\n",
    "        super().__init__()\n",
    "\n",
    "        self.self_attn_layer_norm = nn.LayerNorm(hidden_dim)\n",
    "        self.ff_layer_norm = nn.LayerNorm(hidden_dim)\n",
    "        self.self_attention = MultiHeadAttentionLayer(hidden_dim, n_heads, dropout_ratio)\n",
    "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hidden_dim, pf_dim, dropout_ratio)\n",
    "        self.dropout = nn.Dropout(dropout_ratio)\n",
    "\n",
    "    # 하나의 임베딩이 복제되어 Query, Key, Value로 입력되는 방식\n",
    "    def forward(self, src, src_mask):\n",
    "\n",
    "        # self attention\n",
    "        _src, attn = self.self_attention(src, src, src, src_mask)\n",
    "        src = self.self_attn_layer_norm(src + self.dropout(_src))\n",
    "\n",
    "        # position-wise feedforward\n",
    "        _src = self.positionwise_feedforward(src)\n",
    "        src = self.ff_layer_norm(src + self.dropout(_src))\n",
    "\n",
    "        return src, attn\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, n_layers, n_heads, pf_dim, dropout_ratio):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.tok_embedding = nn.Linear(input_dim, hidden_dim)\n",
    "        self.pos_embedding = nn.Embedding(input_dim, hidden_dim)\n",
    "\n",
    "        self.layers = nn.ModuleList([EncoderLayer(hidden_dim, n_heads, pf_dim, dropout_ratio) for _ in range(n_layers)])\n",
    "        self.dropout = nn.Dropout(dropout_ratio)\n",
    "\n",
    "\n",
    "    def forward(self, src, src_mask):\n",
    "\n",
    "        batch_size = src.shape[0]\n",
    "        src_len = src.shape[1]\n",
    "        device = src.device\n",
    "        pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(device)\n",
    "\n",
    "        self.tok_embedding.to(device)\n",
    "        self.pos_embedding.to(device)\n",
    "        # 소스 문장의 임베딩과 위치 임베딩을 더한 것을 사용\n",
    "        src = self.dropout((self.tok_embedding(src) * math.sqrt(self.hidden_dim)) + self.pos_embedding(pos))\n",
    "        \n",
    "        # 모든 인코더 레이어를 차례대로 거치면서 순전파(forward) 수행\n",
    "        attns = []\n",
    "        for layer in self.layers:\n",
    "            src, attn = layer(src, src_mask)\n",
    "            attns += [attn]\n",
    "\n",
    "        return src, attns # 마지막 레이어의 출력을 반환\n",
    "    \n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, hidden_dim, n_heads, pf_dim, dropout_ratio):\n",
    "        super().__init__()\n",
    "\n",
    "        self.self_attn_layer_norm = nn.LayerNorm(hidden_dim)\n",
    "        self.enc_attn_layer_norm = nn.LayerNorm(hidden_dim)\n",
    "        self.ff_layer_norm = nn.LayerNorm(hidden_dim)\n",
    "        self.self_attention = MultiHeadAttentionLayer(hidden_dim, n_heads, dropout_ratio)\n",
    "        self.encoder_attention = MultiHeadAttentionLayer(hidden_dim, n_heads, dropout_ratio)\n",
    "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hidden_dim, pf_dim, dropout_ratio)\n",
    "        self.dropout = nn.Dropout(dropout_ratio)\n",
    "\n",
    "    # 인코더의 출력 값(enc_src)을 어텐션(attention)하는 구조\n",
    "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
    "\n",
    "        # self attention\n",
    "        _trg, attn_1 = self.self_attention(trg, trg, trg, trg_mask)\n",
    "        trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
    "\n",
    "        # encoder attention\n",
    "        _trg, attn_2 = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
    "        trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
    "\n",
    "        # positionwise feedforward\n",
    "        _trg = self.positionwise_feedforward(trg)\n",
    "        trg = self.ff_layer_norm(trg + self.dropout(_trg))\n",
    "\n",
    "        return trg, attn_1, attn_2\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, hidden_dim, n_layers, n_heads, pf_dim, dropout_ratio):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.tok_embedding = nn.Linear(output_dim, hidden_dim)\n",
    "        self.pos_embedding = nn.Embedding(output_dim, hidden_dim)\n",
    "\n",
    "        self.layers = nn.ModuleList([DecoderLayer(hidden_dim, n_heads, pf_dim, dropout_ratio) for _ in range(n_layers)])\n",
    "\n",
    "        self.fc_out_1 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc_out_2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_ratio)\n",
    "\n",
    "\n",
    "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
    "\n",
    "        device = trg.device\n",
    "        batch_size = trg.shape[0]\n",
    "        trg_len = trg.shape[1]\n",
    "\n",
    "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(device)\n",
    "\n",
    "        trg = self.dropout((self.tok_embedding(trg) * math.sqrt(self.hidden_dim)) + self.pos_embedding(pos))\n",
    "\n",
    "        # trg: [batch_size, trg_len, hidden_dim]\n",
    "        attns_1 = []\n",
    "        attns_2 = []\n",
    "        for layer in self.layers:\n",
    "            trg, attn_1, attn_2 = layer(trg, enc_src, trg_mask, src_mask)\n",
    "            attns_1 += [attn_1]\n",
    "            attns_2 += [attn_2]\n",
    "\n",
    "        trg = self.fc_out_1(trg)\n",
    "        output = self.fc_out_2(trg)\n",
    "\n",
    "        return output, attns_1, attns_2\n",
    "    \n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.trg_sub_mask = torch.tril(torch.ones((10, 10)),diagonal=-1).bool().T.unsqueeze(0)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        Enc_in, Enc_mask, Dec_in, Dec_mask = inputs\n",
    "        \n",
    "        device = Enc_in.device\n",
    "        Dec_mask = Dec_mask.transpose(1,2) + self.trg_sub_mask.to(device)\n",
    "        Enc_mask = Enc_mask.transpose(1,2)\n",
    "\n",
    "        enc_src, enc_attns = self.encoder(Enc_in, Enc_mask)\n",
    "\n",
    "        output, dec_attns_1, dec_attns_2 = self.decoder(Dec_in, enc_src, Dec_mask, Enc_mask)\n",
    "\n",
    "        return output, enc_attns + dec_attns_1 + dec_attns_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "devices = [torch.device(f\"cuda:{i}\") for i in range(2, torch.cuda.device_count())]\n",
    "device = devices[0]\n",
    "dropout_ratio = 0.1\n",
    "\n",
    "input_dim = 100\n",
    "hidden_dim = 512\n",
    "num_layers = 3\n",
    "num_head = 8\n",
    "ff_dim = 2048\n",
    "lr = 1e-4\n",
    "enc = Encoder(input_dim, hidden_dim, num_layers, num_head, pf_dim = ff_dim, dropout_ratio= dropout_ratio)\n",
    "dec = Decoder(input_dim, hidden_dim, num_layers, num_head, pf_dim = ff_dim, dropout_ratio= dropout_ratio)\n",
    "BART_model = Transformer(enc, dec).to(device)\n",
    "optimizer = torch.optim.AdamW(BART_model.parameters(), lr=lr)\n",
    "if len(devices) > 1:\n",
    "    print(\"Let's use\", len(devices), \"GPUs!\")\n",
    "    # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "    BART_model = nn.DataParallel(BART_model, device_ids = devices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_dataloader = DataLoader(BART_pretrain_Dataset([TF_in_data, TF_in_mask, ID_list, ID_year_list, ID_train]),\n",
    "                                batch_size=batch_size, shuffle=True, collate_fn=BART_collate_fn)\n",
    "test_dataloader = DataLoader(BART_pretrain_Dataset([TF_in_data, TF_in_mask, ID_list, ID_year_list, ID_test]),\n",
    "                                batch_size=batch_size, shuffle=True, collate_fn=BART_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 200\n",
    "timer_use = tqdm.tqdm(range(n_epochs))\n",
    "\n",
    "for epoch in timer_use:\n",
    "    loss_train_all = 0\n",
    "    loss_test_all = 0\n",
    "    BART_model.train()\n",
    "    len_train = 0\n",
    "    pear_mask,pear_x,pear_y = [],[],[]\n",
    "    for Enc_in, Enc_mask, Dec_in, Dec_mask, Out_mask, Out_data, IDs in train_dataloader:\n",
    "        Enc_in = Enc_in.to(device) # N,10,26\n",
    "        Dec_in = Dec_in.to(device) # N,10,26\n",
    "        Enc_mask = Enc_mask.to(device) # N,10,1\n",
    "        Dec_mask = Dec_mask.to(device) # N,10,1\n",
    "        Out_mask = Out_mask.to(device)\n",
    "        Out_data = Out_data.to(device)\n",
    "        A,_ = BART_model([Enc_in, Enc_mask, Dec_in, Dec_mask])\n",
    "        len_train += Enc_in.shape[0]\n",
    "        loss_MLM = ((Out_mask)*(A - Out_data)).pow(2).sum()/((Out_mask).sum())\n",
    "        loss = loss_MLM#+loss_Re\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_train_all += loss.item()*Enc_in.shape[0]\n",
    "        \n",
    "    loss_train_all /= len_train\n",
    "    BART_model.eval()\n",
    "    len_test = 0\n",
    "    pear_mask,pear_x,pear_y = [],[],[]\n",
    "    for Enc_in, Enc_mask, Dec_in, Dec_mask, Out_mask, Out_data, IDs in test_dataloader:\n",
    "        Enc_in = Enc_in.to(device) # N,10,26\n",
    "        Dec_in = Dec_in.to(device) # N,10,26\n",
    "        Enc_mask = Enc_mask.to(device) # N,10,1\n",
    "        Dec_mask = Dec_mask.to(device) # N,10,1\n",
    "        Out_mask = Out_mask.to(device)\n",
    "        Out_data = Out_data.to(device)\n",
    "        A,_ = BART_model([Enc_in, Enc_mask, Dec_in, Dec_mask])\n",
    "        len_test += Enc_in.shape[0]\n",
    "        loss_MLM = ((Out_mask)*(A - Out_data)).pow(2).sum()/((Out_mask).sum())\n",
    "        loss = loss_MLM#+loss_Re\n",
    "        optimizer.zero_grad()\n",
    "        loss_test_all += loss.item()*Enc_in.shape[0]\n",
    "        \n",
    "    loss_test_all /= len_test\n",
    "    discript = f\"model B | E {epoch} |\"\n",
    "    discript += f\"Loss :\"\n",
    "    discript += f\"Train : {loss_train_all:.3f} # {len_train} Validate : {loss_test_all:.3f} # {len_test}\"\n",
    "    timer_use.set_description(discript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"model_save\"\n",
    "# save_name = \"230913_pretrained_BART\"\n",
    "save_name = \"250320_pretrained_BART\"\n",
    "torch.save(BART_model, f\"{model_dir}/{save_name}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(50):\n",
    "    A_sub = A_all_val[:,:,i].reshape(-1)[O_mask_all.reshape(-1)]\n",
    "    Data_sub = O_data_all[:,:,i].reshape(-1)[O_mask_all.reshape(-1)]\n",
    "    plt.subplot(8,8,i+1)\n",
    "    max_l = max(np.max(A_sub),np.max(Data_sub))\n",
    "    min_l = min(np.min(A_sub),np.min(Data_sub))\n",
    "    plt.scatter(Data_sub, A_sub, s = 1, alpha = 0.3)\n",
    "    plt.xlim(max_l+0.2,min_l-0.2)\n",
    "    plt.ylim(max_l+0.2,min_l-0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_all_val = []\n",
    "O_data_all = []\n",
    "O_mask_all = []\n",
    "for Enc_in, Enc_mask, Dec_in, Dec_mask, Out_mask, Out_data, IDs in test_dataloader:\n",
    "    Enc_in = Enc_in.to(device) # N,10,26\n",
    "    Dec_in = Dec_in.to(device) # N,10,26\n",
    "    Enc_mask = Enc_mask.to(device) # N,10,1\n",
    "    Dec_mask = Dec_mask.to(device) # N,10,1\n",
    "    Out_mask = Out_mask.to(device)\n",
    "    Out_data = Out_data.to(device)\n",
    "    A,B = BART_model([Enc_in, Enc_mask, Dec_in, Dec_mask])\n",
    "    A_all_val = A.detach().cpu().numpy() if len(A_all_val) == 0 else np.concatenate([A_all_val,A.detach().cpu().numpy()],axis = 0)\n",
    "    O_data_all = Out_data.detach().cpu().numpy() if len(O_data_all) == 0 else np.concatenate([O_data_all,Out_data.detach().cpu().numpy()],axis = 0)\n",
    "    O_mask_all = Out_mask.detach().cpu().numpy() if len(O_mask_all) == 0 else np.concatenate([O_mask_all,Out_mask.detach().cpu().numpy()],axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(50):\n",
    "    A_sub = A_all_val[:,:,i].reshape(-1)[O_mask_all.reshape(-1)]\n",
    "    Data_sub = O_data_all[:,:,i].reshape(-1)[O_mask_all.reshape(-1)]\n",
    "    plt.subplot(8,8,i+1)\n",
    "    max_l = max(np.max(A_sub),np.max(Data_sub))\n",
    "    min_l = min(np.min(A_sub),np.min(Data_sub))\n",
    "    plt.scatter(Data_sub, A_sub, s = 1, alpha = 0.3)\n",
    "    plt.xlim(max_l+0.2,min_l-0.2)\n",
    "    plt.ylim(max_l+0.2,min_l-0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.argmin(Enc_mask.sum(axis = [1,2]).detach().cpu().numpy())\n",
    "for j in range(len(B)):\n",
    "    print(j)\n",
    "    for i in range(8):\n",
    "        plt.subplot(2,4,i+1)\n",
    "        plt.imshow(B[j][idx,i].detach().cpu().numpy(), vmin = 0, vmax = 1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Env_yoo_01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
